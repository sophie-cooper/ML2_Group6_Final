{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings Projections (Linear Model and Matrix Factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "with open(r'\\Users\\Julie\\Documents\\Andrew MBA stuff\\Machine Learning\\Kaggle Project\\Rating\\train.json', 'rb') as f_in:\n",
    "    with gzip.open('train.json.gz', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('train.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewHash</th>\n",
       "      <th>categories</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>categoryID</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>09 26, 2013</td>\n",
       "      <td>The model in this picture has them rolled up a...</td>\n",
       "      <td>{'nHelpful': 0, 'outOf': 0}</td>\n",
       "      <td>U490934656</td>\n",
       "      <td>R798569390</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women], [Clothing...</td>\n",
       "      <td>1380153600</td>\n",
       "      <td>I402344648</td>\n",
       "      <td>4.0</td>\n",
       "      <td>High Waisted</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>02 7, 2013</td>\n",
       "      <td>I love the look of this bra, it is what I want...</td>\n",
       "      <td>{'nHelpful': 0, 'outOf': 0}</td>\n",
       "      <td>U714157797</td>\n",
       "      <td>R436443063</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Clothing, ...</td>\n",
       "      <td>1360195200</td>\n",
       "      <td>I697650540</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Beautiful but size runs small</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03 16, 2014</td>\n",
       "      <td>I am not comfortable with wearing my wedding b...</td>\n",
       "      <td>{'nHelpful': 0, 'outOf': 0}</td>\n",
       "      <td>U507366950</td>\n",
       "      <td>R103439446</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Wedding Party Gif...</td>\n",
       "      <td>1394928000</td>\n",
       "      <td>I464613034</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great Alternative for Nurses</td>\n",
       "      <td>0</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03 10, 2014</td>\n",
       "      <td>Like the look of this top and really looks cut...</td>\n",
       "      <td>{'nHelpful': 0, 'outOf': 0}</td>\n",
       "      <td>U307862152</td>\n",
       "      <td>R486351639</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Clothing, ...</td>\n",
       "      <td>1394409600</td>\n",
       "      <td>I559560885</td>\n",
       "      <td>2.0</td>\n",
       "      <td>One size fits all...Questionable</td>\n",
       "      <td>0</td>\n",
       "      <td>18.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>07 30, 2013</td>\n",
       "      <td>I'm quite small and the XS fits me like a regu...</td>\n",
       "      <td>{'nHelpful': 1, 'outOf': 1}</td>\n",
       "      <td>U742726598</td>\n",
       "      <td>R508664275</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Plus-Size,...</td>\n",
       "      <td>1375142400</td>\n",
       "      <td>I476005312</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great shirt</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199995</td>\n",
       "      <td>01 26, 2013</td>\n",
       "      <td>Looks just like the picture and the item arriv...</td>\n",
       "      <td>{'nHelpful': 0, 'outOf': 0}</td>\n",
       "      <td>U781794983</td>\n",
       "      <td>R285432298</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Clothing, ...</td>\n",
       "      <td>1359158400</td>\n",
       "      <td>I245323432</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cute</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199996</td>\n",
       "      <td>04 2, 2013</td>\n",
       "      <td>I'm a C cup and the C cup in this is way too s...</td>\n",
       "      <td>{'nHelpful': 1, 'outOf': 1}</td>\n",
       "      <td>U151975942</td>\n",
       "      <td>R454986738</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Clothing, ...</td>\n",
       "      <td>1364860800</td>\n",
       "      <td>I990230316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not true to Cup size.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199997</td>\n",
       "      <td>09 22, 2012</td>\n",
       "      <td>I have a pair of earrings just like this (only...</td>\n",
       "      <td>{'nHelpful': 0, 'outOf': 0}</td>\n",
       "      <td>U525354881</td>\n",
       "      <td>R088851171</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Jewelry: Internat...</td>\n",
       "      <td>1348272000</td>\n",
       "      <td>I037381245</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Lovely, but small</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199998</td>\n",
       "      <td>12 27, 2013</td>\n",
       "      <td>My granddaughter love the scarf and fit perfec...</td>\n",
       "      <td>{'nHelpful': 0, 'outOf': 1}</td>\n",
       "      <td>U995566285</td>\n",
       "      <td>R524991477</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Women, Accessorie...</td>\n",
       "      <td>1388102400</td>\n",
       "      <td>I343675670</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Scarf</td>\n",
       "      <td>0</td>\n",
       "      <td>7.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199999</td>\n",
       "      <td>03 1, 2014</td>\n",
       "      <td>My baby wore it only one time and there are ho...</td>\n",
       "      <td>{'nHelpful': 1, 'outOf': 2}</td>\n",
       "      <td>U994496485</td>\n",
       "      <td>R695913313</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Baby, Baby Girls,...</td>\n",
       "      <td>1393632000</td>\n",
       "      <td>I757871532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very bad!</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reviewTime                                         reviewText  \\\n",
       "0       09 26, 2013  The model in this picture has them rolled up a...   \n",
       "1        02 7, 2013  I love the look of this bra, it is what I want...   \n",
       "2       03 16, 2014  I am not comfortable with wearing my wedding b...   \n",
       "3       03 10, 2014  Like the look of this top and really looks cut...   \n",
       "4       07 30, 2013  I'm quite small and the XS fits me like a regu...   \n",
       "...             ...                                                ...   \n",
       "199995  01 26, 2013  Looks just like the picture and the item arriv...   \n",
       "199996   04 2, 2013  I'm a C cup and the C cup in this is way too s...   \n",
       "199997  09 22, 2012  I have a pair of earrings just like this (only...   \n",
       "199998  12 27, 2013  My granddaughter love the scarf and fit perfec...   \n",
       "199999   03 1, 2014  My baby wore it only one time and there are ho...   \n",
       "\n",
       "                            helpful  reviewerID  reviewHash  \\\n",
       "0       {'nHelpful': 0, 'outOf': 0}  U490934656  R798569390   \n",
       "1       {'nHelpful': 0, 'outOf': 0}  U714157797  R436443063   \n",
       "2       {'nHelpful': 0, 'outOf': 0}  U507366950  R103439446   \n",
       "3       {'nHelpful': 0, 'outOf': 0}  U307862152  R486351639   \n",
       "4       {'nHelpful': 1, 'outOf': 1}  U742726598  R508664275   \n",
       "...                             ...         ...         ...   \n",
       "199995  {'nHelpful': 0, 'outOf': 0}  U781794983  R285432298   \n",
       "199996  {'nHelpful': 1, 'outOf': 1}  U151975942  R454986738   \n",
       "199997  {'nHelpful': 0, 'outOf': 0}  U525354881  R088851171   \n",
       "199998  {'nHelpful': 0, 'outOf': 1}  U995566285  R524991477   \n",
       "199999  {'nHelpful': 1, 'outOf': 2}  U994496485  R695913313   \n",
       "\n",
       "                                               categories  unixReviewTime  \\\n",
       "0       [[Clothing, Shoes & Jewelry, Women], [Clothing...      1380153600   \n",
       "1       [[Clothing, Shoes & Jewelry, Women, Clothing, ...      1360195200   \n",
       "2       [[Clothing, Shoes & Jewelry, Wedding Party Gif...      1394928000   \n",
       "3       [[Clothing, Shoes & Jewelry, Women, Clothing, ...      1394409600   \n",
       "4       [[Clothing, Shoes & Jewelry, Women, Plus-Size,...      1375142400   \n",
       "...                                                   ...             ...   \n",
       "199995  [[Clothing, Shoes & Jewelry, Women, Clothing, ...      1359158400   \n",
       "199996  [[Clothing, Shoes & Jewelry, Women, Clothing, ...      1364860800   \n",
       "199997  [[Clothing, Shoes & Jewelry, Jewelry: Internat...      1348272000   \n",
       "199998  [[Clothing, Shoes & Jewelry, Women, Accessorie...      1388102400   \n",
       "199999  [[Clothing, Shoes & Jewelry, Baby, Baby Girls,...      1393632000   \n",
       "\n",
       "            itemID  rating                           summary  categoryID  \\\n",
       "0       I402344648     4.0                      High Waisted           0   \n",
       "1       I697650540     4.0     Beautiful but size runs small           0   \n",
       "2       I464613034     5.0      Great Alternative for Nurses           0   \n",
       "3       I559560885     2.0  One size fits all...Questionable           0   \n",
       "4       I476005312     5.0                       Great shirt           0   \n",
       "...            ...     ...                               ...         ...   \n",
       "199995  I245323432     5.0                              Cute           0   \n",
       "199996  I990230316     1.0             Not true to Cup size.           0   \n",
       "199997  I037381245     4.0                 Lovely, but small           0   \n",
       "199998  I343675670     5.0                             Scarf           0   \n",
       "199999  I757871532     1.0                         Very bad!           4   \n",
       "\n",
       "        price  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2       19.99  \n",
       "3       18.99  \n",
       "4         NaN  \n",
       "...       ...  \n",
       "199995    NaN  \n",
       "199996    NaN  \n",
       "199997  34.99  \n",
       "199998   7.50  \n",
       "199999    NaN  \n",
       "\n",
       "[200000 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>U490934656</td>\n",
       "      <td>I402344648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>U714157797</td>\n",
       "      <td>I697650540</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>U507366950</td>\n",
       "      <td>I464613034</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>U307862152</td>\n",
       "      <td>I559560885</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>U742726598</td>\n",
       "      <td>I476005312</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199995</td>\n",
       "      <td>U781794983</td>\n",
       "      <td>I245323432</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199996</td>\n",
       "      <td>U151975942</td>\n",
       "      <td>I990230316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199997</td>\n",
       "      <td>U525354881</td>\n",
       "      <td>I037381245</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199998</td>\n",
       "      <td>U995566285</td>\n",
       "      <td>I343675670</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199999</td>\n",
       "      <td>U994496485</td>\n",
       "      <td>I757871532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewerID      itemID rating\n",
       "0       U490934656  I402344648      4\n",
       "1       U714157797  I697650540      4\n",
       "2       U507366950  I464613034      5\n",
       "3       U307862152  I559560885      2\n",
       "4       U742726598  I476005312      5\n",
       "...            ...         ...    ...\n",
       "199995  U781794983  I245323432      5\n",
       "199996  U151975942  I990230316      1\n",
       "199997  U525354881  I037381245      4\n",
       "199998  U995566285  I343675670      5\n",
       "199999  U994496485  I757871532      1\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "input_data = df\n",
    "input_data['reviewerID'] = input_data['reviewerID'].astype(object) # fix datatype error\n",
    "input_data['itemID'] = input_data['itemID'].astype(object) # fix datatype error\n",
    "input_data['rating'] = input_data['rating'].astype(object) # fix datatype error\n",
    "\n",
    "dataset = {\"reviewerID\": input_data[\"reviewerID\"], \"itemID\": input_data[\"itemID\"], \"rating\": input_data[\"rating\"]  }\n",
    "dataset = pd.DataFrame(data = dataset)\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# dataset = dataset[dataset[\"overall\"] != '3'] # need datatype=object\n",
    "#dataset[\"label\"] = dataset[\"rating\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(f):\n",
    "    for l in open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['reviewerID']=dataset['reviewerID'].str[1:]\n",
    "dataset['itemID']=dataset['itemID'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>490934656</td>\n",
       "      <td>402344648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>714157797</td>\n",
       "      <td>697650540</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>507366950</td>\n",
       "      <td>464613034</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>307862152</td>\n",
       "      <td>559560885</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>742726598</td>\n",
       "      <td>476005312</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199995</td>\n",
       "      <td>781794983</td>\n",
       "      <td>245323432</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199996</td>\n",
       "      <td>151975942</td>\n",
       "      <td>990230316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199997</td>\n",
       "      <td>525354881</td>\n",
       "      <td>037381245</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199998</td>\n",
       "      <td>995566285</td>\n",
       "      <td>343675670</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199999</td>\n",
       "      <td>994496485</td>\n",
       "      <td>757871532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID     itemID rating\n",
       "0       490934656  402344648      4\n",
       "1       714157797  697650540      4\n",
       "2       507366950  464613034      5\n",
       "3       307862152  559560885      2\n",
       "4       742726598  476005312      5\n",
       "...           ...        ...    ...\n",
       "199995  781794983  245323432      5\n",
       "199996  151975942  990230316      1\n",
       "199997  525354881  037381245      4\n",
       "199998  995566285  343675670      5\n",
       "199999  994496485  757871532      1\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(r'\\Users\\Julie\\Documents\\Andrew MBA stuff\\Machine Learning\\Kaggle Project\\Rating\\train_ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and Edit CSV FILE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sample = 200000\n",
    "train_sample = 150000\n",
    "\n",
    "allRatings = np.zeros(total_sample)   # store all ratings\n",
    "train_user_diction = {}   # store data using userID as keys\n",
    "train_item_diction = {}   # store data using itemID as keys\n",
    "test_user_diction = {}   # store data using userID as keys\n",
    "test_item_diction = {}   # store data using itemID as keys\n",
    "data = np.zeros((total_sample, 3), dtype=object) # store entire data as an array\n",
    "\n",
    "\n",
    "reader = csv.reader(open(r\"\\Users\\Julie\\Documents\\Andrew MBA stuff\\Machine Learning\\Kaggle Project\\Rating\\train_ratings.csv\", 'r', encoding = \"ISO-8859-1\"), delimiter=',')\n",
    "next(reader) # to skip the first line\n",
    "\n",
    "for index, row in enumerate(reader):\n",
    "    allRatings[index] = float(row[-1])\n",
    "    data[index] = row\n",
    "    if index < train_sample:\n",
    "        if row[0] not in train_user_diction:\n",
    "            train_user_diction[row[0]] = [row[1:]]\n",
    "        else:\n",
    "            train_user_diction[row[0]].append(row[1:])\n",
    "        if row[1] not in train_item_diction:\n",
    "            train_item_diction[row[1]] = [[row[0], row[2]]]\n",
    "        else:\n",
    "            train_item_diction[row[1]].append([row[0], row[2]])\n",
    "    else:\n",
    "        if row[0] not in test_user_diction:\n",
    "            test_user_diction[row[0]] = [row[1:]]\n",
    "        else:\n",
    "            test_user_diction[row[0]].append(row[1:])\n",
    "        if row[1] not in test_item_diction:\n",
    "            test_item_diction[row[1]] = [[row[0], row[2]]]\n",
    "        else:\n",
    "            test_item_diction[row[1]].append([row[0], row[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1: only alpha\n",
    "alpha = np.mean(allRatings[:train_sample])/1.00205\n",
    "test_error = mse(allRatings[train_sample:], [alpha]*(total_sample - train_sample))\n",
    "train_error = mse(allRatings[:train_sample], [alpha]*train_sample)\n",
    "print('model 1 alpha', alpha) \n",
    "print('model 1 train mse', train_error)\n",
    "print('model 1 train rmse', np.sqrt(train_error))\n",
    "print('model 1 testing mse', test_error)\n",
    "print('model 1 testing rmse', np.sqrt(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2: alpha and beta_u\n",
    "\n",
    "# initialize alpha and beta\n",
    "train_user_list = list(train_user_diction.keys())\n",
    "alpha_2 = 0\n",
    "beta_u = {}\n",
    "delta = 10  # difference between iterations\n",
    "while delta >= 1000**-5: # set the error tolerance \n",
    "    local_alpha = 0\n",
    "    for user in train_user_list:   # we first update alpha\n",
    "        user_rating = np.array(train_user_diction[user])[:,1]        \n",
    "        if user not in beta_u:\n",
    "            local_alpha += np.sum(user_rating.astype(float))\n",
    "        else:\n",
    "            local_alpha += np.sum(user_rating.astype(float) - beta_u[user])/2.5\n",
    "    local_alpha = local_alpha/train_sample\n",
    "    \n",
    "    for user in train_user_list:  # we then update beta\n",
    "        user_rating = np.array(train_user_diction[user])[:,1]\n",
    "        beta_u[user] = np.sum(user_rating.astype(float) - local_alpha)/len(train_user_diction[user])\n",
    "    \n",
    "    delta = abs(local_alpha - alpha_2)  # calculate the difference of alphas between epoch\n",
    "    alpha_2 = local_alpha # update global alpha\n",
    "    print(alpha_2)\n",
    "\n",
    "print(alpha_2)\n",
    "\n",
    "##### calculate training mse and testing mse #######################################################\n",
    "test_user_list = list(test_user_diction.keys())\n",
    "train_label = np.zeros(train_sample)\n",
    "train_prediction = np.zeros(train_sample)\n",
    "test_label = np.zeros(total_sample-train_sample)\n",
    "test_prediction = np.zeros(total_sample - train_sample)\n",
    "index = 0\n",
    "for user in train_user_list:\n",
    "    user_rating = np.array(train_user_diction[user])[:,1].astype(float)\n",
    "    train_label[index: index+len(user_rating)] = user_rating\n",
    "    train_prediction[index: index+len(user_rating)] = alpha_2 + beta_u[user]\n",
    "    index += len(user_rating)\n",
    "\n",
    "index = 0\n",
    "for user in test_user_list:\n",
    "    user_rating = np.array(test_user_diction[user])[:,1].astype(float)\n",
    "    test_label[index: index+len(user_rating)] = user_rating\n",
    "    if user not in train_user_list:\n",
    "        test_prediction[index: index+len(user_rating)] = alpha_2\n",
    "    else:\n",
    "        test_prediction[index: index+len(user_rating)] = alpha_2 + beta_u[user]\n",
    "    index += len(user_rating)\n",
    "        \n",
    "train_error_2 = mse(train_label, train_prediction)\n",
    "test_error_2 = mse(test_label, test_prediction)\n",
    "print('model 2 train mse', train_error_2)\n",
    "print('model 2 train rmse', np.sqrt(train_error_2))\n",
    "print('model 2 testing mse', test_error_2)\n",
    "print('model 2 testing rmse', np.sqrt(test_error_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_diction[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3: alpha and beta_i\n",
    "\n",
    "# initialize alpha and beta\n",
    "train_item_list = list(train_item_diction.keys())\n",
    "alpha_3 = 0\n",
    "beta_i = {}\n",
    "delta = 10\n",
    "while delta >= 10**-5:\n",
    "    local_alpha = 0\n",
    "    for item in train_item_list: # we first update alpha\n",
    "        item_rating = np.array(train_item_diction[item])[:,1]\n",
    "        if item not in beta_i:\n",
    "            local_alpha += np.sum(item_rating.astype(float))\n",
    "        else:\n",
    "            local_alpha += np.sum(item_rating.astype(float) - beta_i[item])\n",
    "    local_alpha = local_alpha/train_sample\n",
    "    \n",
    "    for item in train_item_list: # we then update beta\n",
    "        item_rating = np.array(train_item_diction[item])[:,1]\n",
    "        beta_i[item] = np.sum(item_rating.astype(float) - local_alpha)/len(train_item_diction[item])\n",
    "    \n",
    "    delta = abs(local_alpha - alpha_3)\n",
    "    alpha_3 = local_alpha\n",
    "    print(alpha_3)\n",
    "\n",
    "\n",
    "test_item_list = list(test_item_diction.keys())\n",
    "train_label = np.zeros(train_sample)\n",
    "train_prediction = np.zeros(train_sample)\n",
    "test_label = np.zeros(total_sample - train_sample)\n",
    "test_prediction = np.zeros(total_sample - train_sample)\n",
    "index = 0\n",
    "for item in tqdm(train_item_list, total = len(train_item_list)):\n",
    "    item_rating = np.array(train_item_diction[item])[:,1].astype(float)\n",
    "    train_label[index: index+len(item_rating)] = item_rating\n",
    "    train_prediction[index: index+len(item_rating)] = alpha_3 + beta_i[item]/2\n",
    "    index += len(item_rating)\n",
    "\n",
    "index = 0\n",
    "for item in tqdm(test_item_list, total = len(test_item_list)):\n",
    "    item_rating = np.array(test_item_diction[item])[:,1].astype(float)\n",
    "    test_label[index: index+len(item_rating)] = item_rating\n",
    "    if item not in train_item_list:\n",
    "        test_prediction[index: index+len(item_rating)] = alpha_3\n",
    "    else:\n",
    "        test_prediction[index: index+len(item_rating)] = alpha_3 + beta_i[item]/2\n",
    "    index += len(item_rating)\n",
    "        \n",
    "train_error_3 = mse(train_label, train_prediction)\n",
    "test_error_3 = mse(test_label, test_prediction)\n",
    "print('model 3 train mse', train_error_3)\n",
    "print('model 3 train rmse', np.sqrt(train_error_3))\n",
    "print('model 3 testing mse', test_error_3)\n",
    "print('model 3 testing rmse', np.sqrt(test_error_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data[:train_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 4: alpha and beta_u and beta_i\n",
    "\n",
    "# initialize alpha and beta\n",
    "alpha_4 = 0\n",
    "beta_u = {}\n",
    "beta_i = {}\n",
    "delta = 10\n",
    "epoch = 0\n",
    "while delta >= 10**-12:\n",
    "    local_alpha = 0\n",
    "    local_beta_u = {}\n",
    "    local_beta_i = {}\n",
    "    \n",
    "    for user, item, rating in data[:train_sample]:  # we first update alpah\n",
    "        if user not in beta_u:\n",
    "            if item not in beta_i:\n",
    "                local_alpha += float(rating)/train_sample\n",
    "            else:\n",
    "                local_alpha += (float(rating) - beta_i[item])/train_sample\n",
    "        else:\n",
    "            if item not in beta_i:\n",
    "                local_alpha += (float(rating) - beta_u[user])/train_sample\n",
    "            else:\n",
    "                local_alpha += (float(rating) - beta_u[user] - beta_i[item])/train_sample\n",
    "    delta = abs(alpha_4 - local_alpha)\n",
    "    alpha_4 = local_alpha\n",
    "    print(alpha_4)\n",
    "    \n",
    "    for user, item, rating in data[:train_sample]:  # we first update beta_u\n",
    "        if item not in beta_i:\n",
    "            if user not in local_beta_u:\n",
    "                local_beta_u[user] = (float(rating) - alpha_4)/len(train_user_diction[user])\n",
    "            else:\n",
    "                local_beta_u[user] += (float(rating) - alpha_4)/len(train_user_diction[user])\n",
    "        else:\n",
    "            if user not in local_beta_u:\n",
    "                local_beta_u[user] = (float(rating) - alpha_4 - beta_i[item])/len(train_user_diction[user])\n",
    "            else:\n",
    "                local_beta_u[user] += (float(rating) - alpha_4 - beta_i[item])/len(train_user_diction[user])\n",
    "    if epoch !=0 :\n",
    "        delta = max(delta, abs(list(local_beta_u.values())[0] - list(beta_u.values())[0]))\n",
    "    beta_u = local_beta_u\n",
    "    \n",
    "    \n",
    "    for user, item, rating in data[:train_sample]:  # we first update beta_i\n",
    "        if item not in local_beta_i:\n",
    "            local_beta_i[item] = (float(rating) - alpha_4 - beta_u[user])/len(train_item_diction[item])\n",
    "        else:\n",
    "            local_beta_i[item] += (float(rating) - alpha_4 - beta_u[user])/len(train_item_diction[item])\n",
    "    \n",
    "    if epoch != 0:\n",
    "        delta = max(delta, abs(list(local_beta_i.values())[0] - list(beta_i.values())[0]))\n",
    "    \n",
    "    beta_i = local_beta_i\n",
    "    epoch += 1\n",
    "\n",
    "\n",
    "train_prediction = np.zeros(train_sample)\n",
    "test_prediction = np.zeros(total_sample - train_sample)\n",
    "for index, (user, item, rating) in tqdm(enumerate(data[:train_sample]), total=train_sample):\n",
    "    train_prediction[index] = alpha_4 + beta_u[user] + beta_i[item]\n",
    "\n",
    "for index, (user, item, rating) in tqdm(enumerate(data[train_sample:]), total=total_sample-train_sample):\n",
    "    if user in beta_u:\n",
    "        if item in beta_i:\n",
    "            test_prediction[index] = alpha_4 + beta_u[user]/2 + beta_i[item]/2\n",
    "        else:\n",
    "            test_prediction[index] = alpha_4 + beta_u[user]/2\n",
    "    else:\n",
    "        if item in beta_i:\n",
    "            test_prediction[index] = alpha_4 + beta_i[item]/2\n",
    "        else:\n",
    "            test_prediction[index] = alpha_4\n",
    "            \n",
    "        \n",
    "train_error_4 = mse(allRatings[:train_sample], train_prediction)\n",
    "test_error_4 = mse(allRatings[train_sample:], test_prediction)\n",
    "print('model 4 train mse', train_error_4)\n",
    "print('model 4 train rmse', np.sqrt(train_error_4))\n",
    "print('model 4 testing mse', test_error_4)\n",
    "print('model 4 testing rmse', np.sqrt(test_error_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_diction[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Model4Output_1.csv\",test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(r\"\\Users\\Julie\\Documents\\Andrew MBA stuff\\Machine Learning\\Kaggle Project\\Rating\\pairs_Rating.txt\", 'w')\n",
    "#reader = csv.reader(open(r\"\\Users\\Julie\\Documents\\Andrew MBA stuff\\Machine Learning\\Kaggle Project\\Rating\\train_ratings.csv\", 'r', encoding = \"ISO-8859-1\"), delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sample = 14000\n",
    "train_sample = 14000\n",
    "\n",
    "allRatings = np.zeros(total_sample)   # store all ratings\n",
    "test2_user_diction = {}   # store data using userID as keys\n",
    "test2_item_diction = {}   # store data using itemID as keys\n",
    "test_user_diction = {}   # store data using userID as keys\n",
    "test_item_diction = {}   # store data using itemID as keys\n",
    "data2 = np.zeros((total_sample, 3), dtype=object) # store entire data as an array\n",
    "\n",
    "\n",
    "next(predictions) # to skip the first line\n",
    "\n",
    "for index, row in enumerate(predictions):\n",
    "    allRatings[index] = float(row[-1])\n",
    "    data2[index] = row\n",
    "    if index < train_sample:\n",
    "        if row[0] not in test2_user_diction:\n",
    "            test2_user_diction[row[0]] = [row[1:]]\n",
    "        else:\n",
    "            test2_user_diction[row[0]].append(row[1:])\n",
    "        if row[1] not in test2_item_diction:\n",
    "            test2_item_diction[row[1]] = [[row[0], row[2]]]\n",
    "        else:\n",
    "            test2_item_diction[row[1]].append([row[0], row[2]])\n",
    "    else:\n",
    "        if row[0] not in test_user_diction:\n",
    "            test_user_diction[row[0]] = [row[1:]]\n",
    "        else:\n",
    "            test_user_diction[row[0]].append(row[1:])\n",
    "        if row[1] not in test_item_diction:\n",
    "            test_item_diction[row[1]] = [[row[0], row[2]]]\n",
    "        else:\n",
    "            test_item_diction[row[1]].append([row[0], row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.4, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nd\n",
    "test_u=list(test_data['reviewerID'])\n",
    "test_i=list(test_data['itemID'])\n",
    "test_r=list(test_data['rating'])\n",
    "train_u=list(train_data['reviewerID'])\n",
    "train_i=list(train_data['itemID'])\n",
    "train_r=list(train_data['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "from mxnet.gluon import nn\n",
    "import mxnet as mx\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from mxnet import autograd, gluon, np, npx\n",
    "npx.set_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024\n",
    "test_set = gluon.data.ArrayDataset(\n",
    "    np.array(test_u), np.array(test_i), np.array(test_r))\n",
    "train_set = gluon.data.ArrayDataset(\n",
    "    np.array(train_u), np.array(train_i), np.array(train_r))\n",
    "test_iter = gluon.data.DataLoader(\n",
    "    test_set, batch_size=batch_size)\n",
    "train_iter = gluon.data.DataLoader(\n",
    "    train_set, shuffle=True, last_batch='rollover',\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'\\Users\\Julie\\Documents\\Andrew MBA stuff\\Machine Learning\\Kaggle Project\\Rating\\train_ratings.csv')\n",
    "data=data.rename(columns={\"reviewerID\":\"user_id\", \"itemID\":\"isbn\", \"ratings\":\"rating\"})\n",
    "num_users = data.user_id.unique().shape[0]\n",
    "num_items = data.isbn.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Block):\n",
    "    def __init__(self, num_factors, num_users, num_items, **kwargs):\n",
    "        super(MF, self).__init__(**kwargs)\n",
    "        self.P = nn.Embedding(input_dim=num_users, output_dim=num_factors)\n",
    "        self.Q = nn.Embedding(input_dim=num_items, output_dim=num_factors)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "\n",
    "    def forward(self, user_id, isbn):\n",
    "        P_u = self.P(user_id)\n",
    "        Q_i = self.Q(isbn)\n",
    "        b_u = self.user_bias(user_id)\n",
    "        b_i = self.item_bias(isbn)\n",
    "        outputs = (P_u * Q_i).sum(axis=1) + np.squeeze(b_i) + np.squeeze(b_u)\n",
    "        return outputs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(net, test_iter, ctx):\n",
    "    rmse = mx.metric.RMSE()  # Get the RMSE\n",
    "    rmse_list = []\n",
    "    for idx, (users, items, ratings) in enumerate(test_iter):\n",
    "        u = gluon.utils.split_and_load(users, ctx, even_split=False)\n",
    "        i = gluon.utils.split_and_load(items, ctx, even_split=False)\n",
    "        r_ui = gluon.utils.split_and_load(ratings, ctx, even_split=False)\n",
    "        r_hat = [net(u, i) for u, i in zip(u, i)]\n",
    "        rmse.update(labels=r_ui, preds=r_hat)\n",
    "        rmse_list.append(rmse.get()[1])\n",
    "    return float(np.mean(np.array(rmse_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved in the d2l package for later use\n",
    "def train_recsys_rating(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "                        ctx_list=d2l.try_all_gpus(), evaluator=None,\n",
    "                        **kwargs):\n",
    "    timer = d2l.Timer()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 2],\n",
    "                            legend=['train loss', 'test RMSE'])\n",
    "    for epoch in range(num_epochs):\n",
    "        metric, l = d2l.Accumulator(3), 0.\n",
    "        for i, values in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            input_data = []\n",
    "            values = values if isinstance(values, list) else [values]\n",
    "            for v in values:\n",
    "                input_data.append(gluon.utils.split_and_load(v, ctx_list))\n",
    "            train_feat = input_data[0:-1] if len(values) > 1 else input_data\n",
    "            train_label = input_data[-1]\n",
    "            with autograd.record():\n",
    "                preds = [net(*t) for t in zip(*train_feat)]\n",
    "                ls = [loss(p, s) for p, s in zip(preds, train_label)]\n",
    "            [l.backward() for l in ls]\n",
    "            l += sum([l.asnumpy() for l in ls]).mean() / len(ctx_list)\n",
    "            trainer.step(values[0].shape[0])\n",
    "            metric.add(l, values[0].shape[0], values[0].size)\n",
    "            timer.stop()\n",
    "        if len(kwargs) > 0:  # it will be used in section AutoRec.\n",
    "            test_rmse = evaluator(net, test_iter, kwargs['inter_mat'],\n",
    "                                  ctx_list)\n",
    "        else:\n",
    "            test_rmse = evaluator(net, test_iter, ctx_list)\n",
    "        train_l = l / (i + 1)\n",
    "        animator.add(epoch + 1, (train_l, test_rmse))\n",
    "    print('train loss %.3f, test RMSE %.3f'\n",
    "          % (metric[0] / metric[1], test_rmse**2))\n",
    "    print('%.1f examples/sec on %s'\n",
    "          % (metric[2] * num_epochs / timer.sum(), ctx_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = d2l.try_all_gpus()\n",
    "num_users, num_items\n",
    "net = MF(30, num_users, num_items)\n",
    "net.initialize(ctx=ctx, force_reinit=True, init=mx.init.Xavier())\n",
    "lr, num_epochs, wd, optimizer = 0.002, 10, .05, 'sgd'\n",
    "loss = gluon.loss.L2Loss()\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer,\n",
    "                        {\"learning_rate\": lr, 'wd': wd})\n",
    "train_recsys_rating(net, train_iter, test_iter, loss, trainer, num_epochs,\n",
    "                    ctx, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_csv(r'\\Users\\Julie\\Documents\\Andrew MBA stuff\\Machine Learning\\Kaggle Project\\Rating\\pairs_Rating.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
